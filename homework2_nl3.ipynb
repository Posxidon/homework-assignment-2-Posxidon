{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "\n",
    "# Stopwords and character names to filter out\n",
    "STOPWORDS = set([\"the\", \"to\", \"and\", \"of\", \"in\", \"his\", \"it\", \"is\", \"you\", \"her\", \"she\", \"he\", \"i\", \"me\", \"my\", \"we\", \"us\"])\n",
    "CHARACTER_NAMES = set([\"tony\", \"steve\", \"natasha\", \"loki\", \"thor\", \"fury\", \"banner\", \"hulk\", \"stark\", \"barton\", \"wanda\", \"clint\", \"peter\", \"ganush\", \"ellen\", \"jack\", \"rham\", \"jas\", \"shaun\", \"milo\", \"trudy\", \"phil\"])\n",
    "\n",
    "# Manually define topic labels (first 5: Avengers, last 5: Drag Me to Hell)\n",
    "TOPIC_LABELS = [\n",
    "    \"Superpowers & Science\", \"Combat & Military\", \"Leadership & Strategy\", \"Technology & Weapons\", \"Tactical Planning\",\n",
    "    \"Supernatural & Curses\", \"Possession & Haunting\", \"Fear & Suspense\", \"Psychological Horror\", \"Demonic Entities\"\n",
    "]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)  # Remove standalone numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS and word not in CHARACTER_NAMES]\n",
    "    return tokens\n",
    "\n",
    "# Load dataset\n",
    "def load_documents(folder):\n",
    "    documents = []\n",
    "    for file in sorted(os.listdir(folder)):\n",
    "        with open(os.path.join(folder, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            documents.append(f.read())\n",
    "    return documents\n",
    "\n",
    "# Get top 10 frequent words per category\n",
    "def get_top_words(docs):\n",
    "    word_counts = Counter()\n",
    "    for doc in docs:\n",
    "        word_counts.update(preprocess_text(doc))\n",
    "    return [word for word, _ in word_counts.most_common(10)]\n",
    "\n",
    "# Run LDA\n",
    "def run_lda(docs, num_topics=10):\n",
    "    tokenized_docs = [preprocess_text(doc) for doc in docs]\n",
    "    dictionary = corpora.Dictionary(tokenized_docs)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=10000)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "    lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15, random_state=42)\n",
    "    return lda_model, dictionary, corpus\n",
    "\n",
    "# Extract topic words per category\n",
    "def get_topic_words(lda_model):\n",
    "    topics = lda_model.show_topics(num_topics=-1, num_words=10, formatted=False)\n",
    "    avengers_topics = {TOPIC_LABELS[i]: [word for word, _ in words] for i, (_, words) in enumerate(topics[:5])}\n",
    "    horror_topics = {TOPIC_LABELS[i + 5]: [word for word, _ in words] for i, (_, words) in enumerate(topics[5:])}\n",
    "    return avengers_topics, horror_topics\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load documents\n",
    "    avengers_docs = load_documents(\"output/avengers\")\n",
    "    horror_docs = load_documents(\"output/drag_me_to_hell\")\n",
    "    \n",
    "    # Compute top words\n",
    "    avengers_top_words = get_top_words(avengers_docs)\n",
    "    horror_top_words = get_top_words(horror_docs)\n",
    "    \n",
    "    print(\"\\nTop 10 Words for Avengers:\\n\", avengers_top_words)\n",
    "    print(\"\\nTop 10 Words for Horror:\\n\", horror_top_words)\n",
    "\n",
    "    # Run LDA\n",
    "    all_docs = avengers_docs + horror_docs\n",
    "    lda_model, dictionary, corpus = run_lda(all_docs, num_topics=10)\n",
    "\n",
    "    # Extract topic words per category\n",
    "    avengers_topics, horror_topics = get_topic_words(lda_model)\n",
    "\n",
    "    print(\"\\nAvengers Topic Words:\\n\", avengers_topics)\n",
    "    print(\"\\nHorror Topic Words:\\n\", horror_topics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
